{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d28337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_io as tfio\n",
    "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5663f43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = \"../datasets/horse2zebra\" # enter path to the dataset\n",
    "image_size = 256 # enter image size\n",
    "batch_size = 8 # enter batch size\n",
    "all_img_path = [str(p) for p in Path(ds_path).rglob('*.jpg')]\n",
    "train_path, test_path = train_test_split(all_img_path, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8891cfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load images and seperate the gray and color channel. this function will be used in tensorflow data pipeline.\n",
    "def load_and_preprocess_images(impath):\n",
    "    im = tf.io.read_file(impath)\n",
    "    colorimg = tf.image.decode_image(im, channels=3)\n",
    "    colorimg = tf.image.resize_with_pad(colorimg, target_height=image_size, target_width=image_size)\n",
    "    colorimg = tf.cast(colorimg, dtype=tf.float32) / 255.0\n",
    "    \n",
    "    labimg = tfio.experimental.color.rgb_to_lab(colorimg)\n",
    "    graypart = tf.expand_dims(labimg[...,0], axis=-1) / 100\n",
    "    colorpart = labimg[...,1:] / 128\n",
    "    \n",
    "    return graypart, colorpart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eba887-3c4d-4245-a94d-ab4b2373071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard data pipeline for train and test dataset\n",
    "ds_train = tf.data.Dataset.from_tensor_slices(train_path)\n",
    "ds_train = ds_train.map(load_and_preprocess_images, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(len(ds_train), seed=42, reshuffle_each_iteration=False)\n",
    "ds_train = ds_train.batch(batch_size)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_test = tf.data.Dataset.from_tensor_slices(test_path)\n",
    "ds_test = ds_test.map(load_and_preprocess_images, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.batch(batch_size)\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ff4291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a sample gray image and its colorful correspondence.\n",
    "sample_input, sample_output = list(ds_train.as_numpy_iterator())[0]\n",
    "grayimg = sample_input\n",
    "colorimg = tfio.experimental.color.lab_to_rgb(np.concatenate((100*grayimg,128*sample_output), axis=-1)).numpy()\n",
    "fig, axs = plt.subplots(batch_size, 2, figsize=(batch_size,4*batch_size))\n",
    "for i in range(batch_size):\n",
    "    axs[i,0].imshow(grayimg[i,...], cmap='gray')\n",
    "    axs[i,1].imshow(colorimg[i,...])\n",
    "    axs[i,0].axis('off')\n",
    "    axs[i,1].axis('off')\n",
    "    axs[i,0].set_title('gray image (input)', size=8)\n",
    "    axs[i,1].set_title('colorful image (GT output)', size=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d5fadb-9600-4550-98b2-89d36e1648d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define auto encoder-decoder network\n",
    "def define_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    # encoder\n",
    "    model.add(Input(shape=(image_size, image_size, 1)))\n",
    "    model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D())\n",
    "\n",
    "    #decoder\n",
    "    model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n",
    "    model.add(UpSampling2D((2,2)))\n",
    "    model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "    model.add(UpSampling2D((2,2)))\n",
    "    model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "    model.add(UpSampling2D((2,2)))\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(2, (3,3), activation='tanh', padding='same'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    return model\n",
    "    \n",
    "model = define_model()\n",
    "model.summary()\n",
    "# tf.keras.utils.plot_model(model)\n",
    "try:\n",
    "    model.load_weights('weights.h5')\n",
    "except FileNotFoundError:\n",
    "    print('weights NOT found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e05f91-229d-484a-98d8-e72b226245e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "checkpoint = ModelCheckpoint(\"weights.h5\", monitor='val_loss', verbose=1, save_weights_only=True, save_best_only=True, mode='min')\n",
    "tensorboard = TensorBoard(log_dir=\"logs\\\\my_saved_model\")\n",
    "callbacks_list = [checkpoint, tensorboard]\n",
    "model.fit(ds_train, validation_data=ds_test, epochs=200, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31aa1e3-190e-4666-9052-ca053a392b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show sample result of model from the test dataset\n",
    "sample_input, sample_output = list(ds_test.as_numpy_iterator())[4]\n",
    "grayimg = sample_input\n",
    "colorimg = tfio.experimental.color.lab_to_rgb(np.concatenate((100*grayimg,128*sample_output), axis=-1)).numpy()\n",
    "pred_colorimg = tfio.experimental.color.lab_to_rgb(np.concatenate((100*grayimg,128*model.predict(grayimg, verbose=0)), axis=-1)).numpy()\n",
    "fig, axs = plt.subplots(batch_size, 3, figsize=(2*batch_size,6*batch_size))\n",
    "for i in range(batch_size):\n",
    "    axs[i,0].imshow(grayimg[i,...], cmap='gray')\n",
    "    axs[i,1].imshow(pred_colorimg[i,...])\n",
    "    axs[i,2].imshow(colorimg[i,...])\n",
    "    axs[i,0].set_title('gray image (input)', size=8)\n",
    "    axs[i,1].set_title('predicted color', size=8)\n",
    "    axs[i,2].set_title('GT color', size=8)\n",
    "    axs[i,0].axis('off')\n",
    "    axs[i,1].axis('off')\n",
    "    axs[i,2].axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
